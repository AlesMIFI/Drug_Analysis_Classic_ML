{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d711093-1b0a-4c43-b8d5-b899981520f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a8aac2-e994-434c-b487-99791aaa6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'данные для моделей.csv' успешно загружен.\n",
      "\n",
      "--- Классификация: превышает ли значение SI пороговое значение 8 (log_SI > log10(8)) ---\n",
      "Пороговое значение SI=8 в логарифмическом масштабе (log10(8)): 0.9031\n",
      "Распределение классов для si_above_8:\n",
      "si_above_8\n",
      "0    623\n",
      "1    344\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Размер обучающей выборки (X_train_si_8_class): (773, 68)\n",
      "Размер тестовой выборки (X_test_si_8_class): (194, 68)\n",
      "Распределение классов в обучающей выборке:\n",
      "si_above_8\n",
      "0    0.644243\n",
      "1    0.355757\n",
      "Name: proportion, dtype: float64\n",
      "Распределение классов в тестовой выборке:\n",
      "si_above_8\n",
      "0    0.64433\n",
      "1    0.35567\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.read_csv(\"данные для моделей.csv\")\n",
    "print(\"DataFrame 'данные для моделей.csv' успешно загружен.\")\n",
    "\n",
    "print(\"\\n--- Классификация: превышает ли значение SI пороговое значение 8 (log_SI > log10(8)) ---\")\n",
    "\n",
    "# 1. Определение целевой переменной для SI > 8\n",
    "target_si_above_8_class = 'si_above_8' # Новая целевая колонка\n",
    "\n",
    "# Порог 8 в логарифмированном масштабе (по основанию 10)\n",
    "threshold_si_log10_8 = np.log10(8)\n",
    "print(f\"Пороговое значение SI=8 в логарифмическом масштабе (log10(8)): {threshold_si_log10_8:.4f}\")\n",
    "\n",
    "# Создаем бинарный столбец: 1, если log_SI > log10(8), иначе 0\n",
    "df_models[target_si_above_8_class] = (df_models['log_SI'] > threshold_si_log10_8).astype(int)\n",
    "\n",
    "print(f\"Распределение классов для {target_si_above_8_class}:\\n{df_models[target_si_above_8_class].value_counts()}\")\n",
    "\n",
    "# Признаки (X) и целевая переменная (y)\n",
    "# Исключаем исходные логарифмированные целевые переменные и только что созданную бинарную целевую переменную.\n",
    "X = df_models.drop(columns=['log_IC50, mM', 'log_CC50, mM', 'log_SI', target_si_above_8_class])\n",
    "y = df_models[target_si_above_8_class]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_si_8_class, X_test_si_8_class, y_train_si_8_class, y_test_si_8_class = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y # stratify=y для сохранения пропорций классов\n",
    ")\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки (X_train_si_8_class): {X_train_si_8_class.shape}\")\n",
    "print(f\"Размер тестовой выборки (X_test_si_8_class): {X_test_si_8_class.shape}\")\n",
    "print(f\"Распределение классов в обучающей выборке:\\n{y_train_si_8_class.value_counts(normalize=True)}\")\n",
    "print(f\"Распределение классов в тестовой выборке:\\n{y_test_si_8_class.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b76cf3-40ac-45fa-ad2d-211b2bef0419",
   "metadata": {},
   "source": [
    "Видим явный дисбаланс классов. Будем использовать балансировку классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b0c148-44c3-40c3-ae9e-aa9fcd3bf145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Рассчитанное значение scale_pos_weight: 1.8109\n"
     ]
    }
   ],
   "source": [
    "# --- Расчет весов классов для моделей ---\n",
    "# Это будет использоваться для LGBM, XGBoost, CatBoost и Keras\n",
    "# ratio = count(negative_class) / count(positive_class)\n",
    "neg_count = y_train_si_8_class.value_counts()[0]\n",
    "pos_count = y_train_si_8_class.value_counts()[1]\n",
    "scale_pos_weight_value = neg_count / pos_count\n",
    "print(f\"\\nРассчитанное значение scale_pos_weight: {scale_pos_weight_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b10f1a-270a-4e61-9e95-c1b5d3fceacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики для GridSearchCV\n",
    "scoring_metrics_class = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': 'f1',\n",
    "    'ROC_AUC': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea15a06a-da0a-47be-adfc-b333c1bedff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Логистическая Регрессия для SI > 8 (классификация) =====\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Лучшие параметры для Логистической Регрессии: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7034995408631772\n",
      "\n",
      "Метрики на тестовой выборке (Логистическая Регрессия):\n",
      "Accuracy: 0.6649\n",
      "F1-score: 0.5806\n",
      "ROC AUC: 0.6991\n",
      "\n",
      "Classification Report (Логистическая Регрессия):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72       125\n",
      "           1       0.52      0.65      0.58        69\n",
      "\n",
      "    accuracy                           0.66       194\n",
      "   macro avg       0.65      0.66      0.65       194\n",
      "weighted avg       0.69      0.66      0.67       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 1: Логистическая Регрессия \n",
    "print(\"\\n===== Логистическая Регрессия для SI > 8 (классификация) =====\")\n",
    "pipeline_lr_class_si_8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear',\n",
    "                                      class_weight='balanced')) # балансировка классов\n",
    "])\n",
    "\n",
    "param_grid_lr_class_si_8 = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search_lr_class_si_8 = GridSearchCV(\n",
    "    pipeline_lr_class_si_8,\n",
    "    param_grid_lr_class_si_8,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lr_class_si_8.fit(X_train_si_8_class, y_train_si_8_class)\n",
    "\n",
    "print(\"Лучшие параметры для Логистической Регрессии:\", grid_search_lr_class_si_8.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_lr_class_si_8.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lr_class_si_8 = grid_search_lr_class_si_8.predict(X_test_si_8_class)\n",
    "y_proba_lr_class_si_8 = grid_search_lr_class_si_8.predict_proba(X_test_si_8_class)[:, 1]\n",
    "\n",
    "accuracy_lr_class_si_8 = accuracy_score(y_test_si_8_class, y_pred_lr_class_si_8)\n",
    "f1_lr_class_si_8 = f1_score(y_test_si_8_class, y_pred_lr_class_si_8)\n",
    "roc_auc_lr_class_si_8 = roc_auc_score(y_test_si_8_class, y_proba_lr_class_si_8)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Логистическая Регрессия):\")\n",
    "print(f\"Accuracy: {accuracy_lr_class_si_8:.4f}\")\n",
    "print(f\"F1-score: {f1_lr_class_si_8:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lr_class_si_8:.4f}\")\n",
    "print(\"\\nClassification Report (Логистическая Регрессия):\")\n",
    "print(classification_report(y_test_si_8_class, y_pred_lr_class_si_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd17fbc3-e93d-41da-8c5a-8e8b8a55fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random Forest Классификатор для SI > 8 (классификация) =====\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Лучшие параметры для Random Forest: {'classifier__max_features': 0.6, 'classifier__min_samples_leaf': 5, 'classifier__n_estimators': 100}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7463399449035812\n",
      "\n",
      "Метрики на тестовой выборке (Random Forest):\n",
      "Accuracy: 0.6959\n",
      "F1-score: 0.5986\n",
      "ROC AUC: 0.7212\n",
      "\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76       125\n",
      "           1       0.56      0.64      0.60        69\n",
      "\n",
      "    accuracy                           0.70       194\n",
      "   macro avg       0.67      0.68      0.68       194\n",
      "weighted avg       0.71      0.70      0.70       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 2: Random Forest Классификатор \n",
    "print(\"\\n===== Random Forest Классификатор для SI > 8 (классификация) =====\")\n",
    "pipeline_rf_class_si_8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42,\n",
    "                                          class_weight='balanced')) #  балансировка классов\n",
    "])\n",
    "\n",
    "param_grid_rf_class_si_8 = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_features': [0.6, 0.8, 1.0],\n",
    "    'classifier__min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "grid_search_rf_class_si_8 = GridSearchCV(\n",
    "    pipeline_rf_class_si_8,\n",
    "    param_grid_rf_class_si_8,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf_class_si_8.fit(X_train_si_8_class, y_train_si_8_class)\n",
    "\n",
    "print(\"Лучшие параметры для Random Forest:\", grid_search_rf_class_si_8.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_rf_class_si_8.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_rf_class_si_8 = grid_search_rf_class_si_8.predict(X_test_si_8_class)\n",
    "y_proba_rf_class_si_8 = grid_search_rf_class_si_8.predict_proba(X_test_si_8_class)[:, 1]\n",
    "\n",
    "accuracy_rf_class_si_8 = accuracy_score(y_test_si_8_class, y_pred_rf_class_si_8)\n",
    "f1_rf_class_si_8 = f1_score(y_test_si_8_class, y_pred_rf_class_si_8)\n",
    "roc_auc_rf_class_si_8 = roc_auc_score(y_test_si_8_class, y_proba_rf_class_si_8)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Random Forest):\")\n",
    "print(f\"Accuracy: {accuracy_rf_class_si_8:.4f}\")\n",
    "print(f\"F1-score: {f1_rf_class_si_8:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_rf_class_si_8:.4f}\")\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test_si_8_class, y_pred_rf_class_si_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40658465-b27b-44f5-a565-e30785f90446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LightGBM Классификатор для SI > 8 (классификация) =====\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Лучшие параметры для LightGBM: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 100, 'classifier__num_leaves': 31, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7440582185491276\n",
      "\n",
      "Метрики на тестовой выборке (LightGBM):\n",
      "Accuracy: 0.6907\n",
      "F1-score: 0.5890\n",
      "ROC AUC: 0.7177\n",
      "\n",
      "Classification Report (LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       125\n",
      "           1       0.56      0.62      0.59        69\n",
      "\n",
      "    accuracy                           0.69       194\n",
      "   macro avg       0.67      0.68      0.67       194\n",
      "weighted avg       0.70      0.69      0.69       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Модель 3: LightGBM Классификатор\n",
    "print(\"\\n===== LightGBM Классификатор для SI > 8 (классификация) =====\")\n",
    "pipeline_lgbm_class_si_8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LGBMClassifier(random_state=42, verbose=-1,\n",
    "                                  scale_pos_weight=scale_pos_weight_value)) #  балансировка классов\n",
    "])\n",
    "\n",
    "param_grid_lgbm_class_si_8 = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__num_leaves': [20, 31],\n",
    "    'classifier__reg_alpha': [0.1, 0.5],\n",
    "    'classifier__reg_lambda': [0.1, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_lgbm_class_si_8 = GridSearchCV(\n",
    "    pipeline_lgbm_class_si_8,\n",
    "    param_grid_lgbm_class_si_8,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lgbm_class_si_8.fit(X_train_si_8_class, y_train_si_8_class)\n",
    "\n",
    "print(\"Лучшие параметры для LightGBM:\", grid_search_lgbm_class_si_8.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_lgbm_class_si_8.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lgbm_class_si_8 = grid_search_lgbm_class_si_8.predict(X_test_si_8_class)\n",
    "y_proba_lgbm_class_si_8 = grid_search_lgbm_class_si_8.predict_proba(X_test_si_8_class)[:, 1]\n",
    "\n",
    "accuracy_lgbm_class_si_8 = accuracy_score(y_test_si_8_class, y_pred_lgbm_class_si_8)\n",
    "f1_lgbm_class_si_8 = f1_score(y_test_si_8_class, y_pred_lgbm_class_si_8)\n",
    "roc_auc_lgbm_class_si_8 = roc_auc_score(y_test_si_8_class, y_proba_lgbm_class_si_8)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (LightGBM):\")\n",
    "print(f\"Accuracy: {accuracy_lgbm_class_si_8:.4f}\")\n",
    "print(f\"F1-score: {f1_lgbm_class_si_8:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lgbm_class_si_8:.4f}\")\n",
    "print(\"\\nClassification Report (LightGBM):\")\n",
    "print(classification_report(y_test_si_8_class, y_pred_lgbm_class_si_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6054ff8b-70ad-491c-ba98-220af5b704f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== XGBoost Классификатор для SI > 8 (классификация) =====\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:53:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для XGBoost: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 0.7}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7490370982552801\n",
      "\n",
      "Метрики на тестовой выборке (XGBoost):\n",
      "Accuracy: 0.6753\n",
      "F1-score: 0.5882\n",
      "ROC AUC: 0.7201\n",
      "\n",
      "Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73       125\n",
      "           1       0.54      0.65      0.59        69\n",
      "\n",
      "    accuracy                           0.68       194\n",
      "   macro avg       0.66      0.67      0.66       194\n",
      "weighted avg       0.69      0.68      0.68       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 4: XGBoost Классификатор\n",
    "print(\"\\n===== XGBoost Классификатор для SI > 8 (классификация) =====\")\n",
    "pipeline_xgb_class_si_8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss',\n",
    "                                 scale_pos_weight=scale_pos_weight_value)) #  балансировка классов\n",
    "])\n",
    "\n",
    "param_grid_xgb_class_si_8 = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__subsample': [0.7, 1.0],\n",
    "    'classifier__colsample_bytree': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgb_class_si_8 = GridSearchCV(\n",
    "    pipeline_xgb_class_si_8,\n",
    "    param_grid_xgb_class_si_8,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_xgb_class_si_8.fit(X_train_si_8_class, y_train_si_8_class)\n",
    "\n",
    "print(\"Лучшие параметры для XGBoost:\", grid_search_xgb_class_si_8.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_xgb_class_si_8.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_xgb_class_si_8 = grid_search_xgb_class_si_8.predict(X_test_si_8_class)\n",
    "y_proba_xgb_class_si_8 = grid_search_xgb_class_si_8.predict_proba(X_test_si_8_class)[:, 1]\n",
    "\n",
    "accuracy_xgb_class_si_8 = accuracy_score(y_test_si_8_class, y_pred_xgb_class_si_8)\n",
    "f1_xgb_class_si_8 = f1_score(y_test_si_8_class, y_pred_xgb_class_si_8)\n",
    "roc_auc_xgb_class_si_8 = roc_auc_score(y_test_si_8_class, y_proba_xgb_class_si_8)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (XGBoost):\")\n",
    "print(f\"Accuracy: {accuracy_xgb_class_si_8:.4f}\")\n",
    "print(f\"F1-score: {f1_xgb_class_si_8:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_xgb_class_si_8:.4f}\")\n",
    "print(\"\\nClassification Report (XGBoost):\")\n",
    "print(classification_report(y_test_si_8_class, y_pred_xgb_class_si_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59411d12-86cb-4a90-92f9-87a66202fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CatBoost Классификатор для SI > 8 (классификация) =====\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Лучшие параметры для CatBoost: {'classifier__depth': 6, 'classifier__iterations': 100, 'classifier__l2_leaf_reg': 3, 'classifier__learning_rate': 0.05}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.747685583103765\n",
      "\n",
      "Метрики на тестовой выборке (CatBoost):\n",
      "Accuracy: 0.6701\n",
      "F1-score: 0.5789\n",
      "ROC AUC: 0.7007\n",
      "\n",
      "Classification Report (CatBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       125\n",
      "           1       0.53      0.64      0.58        69\n",
      "\n",
      "    accuracy                           0.67       194\n",
      "   macro avg       0.65      0.66      0.65       194\n",
      "weighted avg       0.69      0.67      0.68       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 5: CatBoost Классификатор \n",
    "print(\"\\n===== CatBoost Классификатор для SI > 8 (классификация) =====\")\n",
    "pipeline_cat_class_si_8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', CatBoostClassifier(random_state=42, verbose=0,\n",
    "                                      auto_class_weights='Balanced')) #  балансировка классов\n",
    "])\n",
    "\n",
    "param_grid_cat_class_si_8 = {\n",
    "    'classifier__iterations': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__depth': [4, 6],\n",
    "    'classifier__l2_leaf_reg': [1, 3]\n",
    "}\n",
    "\n",
    "grid_search_cat_class_si_8 = GridSearchCV(\n",
    "    pipeline_cat_class_si_8,\n",
    "    param_grid_cat_class_si_8,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_cat_class_si_8.fit(X_train_si_8_class, y_train_si_8_class)\n",
    "\n",
    "print(\"Лучшие параметры для CatBoost:\", grid_search_cat_class_si_8.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_cat_class_si_8.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_cat_class_si_8 = grid_search_cat_class_si_8.predict(X_test_si_8_class)\n",
    "y_proba_cat_class_si_8 = grid_search_cat_class_si_8.predict_proba(X_test_si_8_class)[:, 1]\n",
    "\n",
    "accuracy_cat_class_si_8 = accuracy_score(y_test_si_8_class, y_pred_cat_class_si_8)\n",
    "f1_cat_class_si_8 = f1_score(y_test_si_8_class, y_pred_cat_class_si_8)\n",
    "roc_auc_cat_class_si_8 = roc_auc_score(y_test_si_8_class, y_proba_cat_class_si_8)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (CatBoost):\")\n",
    "print(f\"Accuracy: {accuracy_cat_class_si_8:.4f}\")\n",
    "print(f\"F1-score: {f1_cat_class_si_8:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_cat_class_si_8:.4f}\")\n",
    "print(\"\\nClassification Report (CatBoost):\")\n",
    "print(classification_report(y_test_si_8_class, y_pred_cat_class_si_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae28825-80cf-4dcc-945d-45bd860a4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Простая Нейронная Сеть для SI > 8 (классификация) =====\n",
      "Веса классов для Нейронной Сети: {0: 1.0, 1: 1.8109090909090908}\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для Нейронной Сети: {'classifier__activation': 'relu', 'classifier__batch_size': 64, 'classifier__epochs': 50, 'classifier__hidden_layers': 2, 'classifier__learning_rate': 0.001, 'classifier__neurons': 32, 'classifier__optimizer': 'adam'}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7345454440792314\n",
      "\n",
      "Метрики на тестовой выборке (Нейронная Сеть):\n",
      "Accuracy: 0.6186\n",
      "F1-score: 0.5195\n",
      "ROC AUC: 0.6635\n",
      "\n",
      "Classification Report (Нейронная Сеть):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68       125\n",
      "           1       0.47      0.58      0.52        69\n",
      "\n",
      "    accuracy                           0.62       194\n",
      "   macro avg       0.60      0.61      0.60       194\n",
      "weighted avg       0.64      0.62      0.63       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 6: Простая Нейронная Сеть (Keras Sequential) \n",
    "print(\"\\n===== Простая Нейронная Сеть для SI > 8 (классификация) =====\")\n",
    "\n",
    "# Функция для создания Keras-модели (используем ту же, что и раньше)\n",
    "def build_nn_model_class(meta, hidden_layers=1, neurons=32, activation='relu',\n",
    "                         optimizer='adam', learning_rate=0.001):\n",
    "    n_features = meta[\"n_features_in_\"]\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(L.Input(shape=(n_features,)))\n",
    "    \n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(L.Dense(neurons, activation=activation))\n",
    "        \n",
    "    model.add(L.Dense(1, activation='sigmoid')) # Sigmoid для бинарной классификации\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#  class_weight непосредственно в метод fit() \n",
    "# Scikeras (обертка KerasClassifier) позволяет передавать class_weight в KerasClassifier.\n",
    "\n",
    "# Сначала, создадим словарь весов классов\n",
    "class_weights_nn = {0: 1.0, 1: scale_pos_weight_value}\n",
    "print(f\"Веса классов для Нейронной Сети: {class_weights_nn}\")\n",
    "\n",
    "pipeline_nn_class_si_8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KerasClassifier(\n",
    "        model=build_nn_model_class,\n",
    "        hidden_layers=1,\n",
    "        neurons=32,\n",
    "        activation='relu',\n",
    "        optimizer='adam',\n",
    "        learning_rate=0.001,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        loss='binary_crossentropy',\n",
    "        class_weight=class_weights_nn #  балансировка классов\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid_nn_class_si_8 = {\n",
    "    'classifier__hidden_layers': [1, 2],\n",
    "    'classifier__neurons': [32, 64],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__optimizer': ['adam'],\n",
    "    'classifier__learning_rate': [0.001, 0.01],\n",
    "    'classifier__batch_size': [32, 64],\n",
    "    'classifier__epochs': [50, 100]\n",
    "}\n",
    "\n",
    "grid_search_nn_class_si_8 = GridSearchCV(\n",
    "    pipeline_nn_class_si_8,\n",
    "    param_grid_nn_class_si_8,\n",
    "    cv=3, # Уменьшаем CV для скорости NN\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_nn_class_si_8.fit(X_train_si_8_class, y_train_si_8_class)\n",
    "\n",
    "print(\"Лучшие параметры для Нейронной Сети:\", grid_search_nn_class_si_8.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_nn_class_si_8.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_nn_class_si_8 = grid_search_nn_class_si_8.predict(X_test_si_8_class)\n",
    "y_proba_nn_class_si_8 = grid_search_nn_class_si_8.predict_proba(X_test_si_8_class)[:, 1]\n",
    "\n",
    "accuracy_nn_class_si_8 = accuracy_score(y_test_si_8_class, y_pred_nn_class_si_8)\n",
    "f1_nn_class_si_8 = f1_score(y_test_si_8_class, y_pred_nn_class_si_8)\n",
    "roc_auc_nn_class_si_8 = roc_auc_score(y_test_si_8_class, y_proba_nn_class_si_8)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Нейронная Сеть):\")\n",
    "print(f\"Accuracy: {accuracy_nn_class_si_8:.4f}\")\n",
    "print(f\"F1-score: {f1_nn_class_si_8:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_nn_class_si_8:.4f}\")\n",
    "print(\"\\nClassification Report (Нейронная Сеть):\")\n",
    "print(classification_report(y_test_si_8_class, y_pred_nn_class_si_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d401f-b041-4fa9-bbea-7407ee8f65c0",
   "metadata": {},
   "source": [
    "Распределение классов для si_above_8 является несбалансированным: класс 0 (SI <= 8) содержит 623 образца, а класс 1 (SI > 8) — 344 образца. В обучающей и тестовой выборках это соотношение сохраняется (примерно 64.4% для класса 0 и 35.6% для класса 1). Для компенсации этого дисбаланса был рассчитан scale_pos_weight со значением 1.8109.\n",
    "\n",
    "1. Логистическая Регрессия\n",
    "Лучшие параметры: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7035\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6649\n",
    "F1-score: 0.5806\n",
    "ROC AUC: 0.6991\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.78 / 0.52\n",
    "Recall (класс 0 / класс 1): 0.67 / 0.65\n",
    "F1-score (класс 0 / класс 1): 0.72 / 0.58\n",
    "Логистическая регрессия показала ROC AUC 0.6991 на тестовой выборке, что является одним из самых высоких значений среди всех моделей для данной задачи. Accuracy составила 0.6649. Из отчёта по классификации видно, что F1-score для класса 1 (0.58) значительно ниже, чем для класса 0 (0.72). Это связано с низкой Precision для класса 1 (0.52), несмотря на относительно неплохой Recall (0.65). Модель склонна к ложным срабатываниям для класса 1.\n",
    "\n",
    "2. Random Forest Классификатор\n",
    "Лучшие параметры: {'classifier__max_features': 0.6, 'classifier__min_samples_leaf': 5, 'classifier__n_estimators': 100}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7463\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6959\n",
    "F1-score: 0.5986\n",
    "ROC AUC: 0.7212\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.78 / 0.56\n",
    "Recall (класс 0 / класс 1): 0.73 / 0.64\n",
    "F1-score (класс 0 / класс 1): 0.76 / 0.60\n",
    "Анализ: Random Forest показал лучшие результаты по ROC AUC (0.7212) и Accuracy (0.6959) на тестовой выборке. F1-score для класса 1 (0.60) немного выше, чем у логистической регрессии, но всё ещё остаётся невысоким из-за низкой Precision (0.56) для этого класса. Модель демонстрирует лучшее равновесие между Precision и Recall для класса 1 по сравнению с Логистической регрессией.\n",
    "\n",
    "3. LightGBM Классификатор\n",
    "Лучшие параметры: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 100, 'classifier__num_leaves': 31, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7441\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6907\n",
    "F1-score: 0.5890\n",
    "ROC AUC: 0.7177\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.78 / 0.56\n",
    "Recall (класс 0 / класс 1): 0.73 / 0.62\n",
    "F1-score (класс 0 / класс 1): 0.75 / 0.59\n",
    "Анализ: LightGBM показал ROC AUC 0.7177 на тестовой выборке, близкий к Random Forest. Accuracy (0.6907) и F1-score (0.5890) также сопоставимы. Отчет по классификации демонстрирует схожую картину с Random Forest: высокая Precision для класса 0 (0.78) и относительно низкая Precision для класса 1 (0.56), указывающая на трудности в точной идентификации положительного класса.\n",
    "\n",
    "4. XGBoost Классификатор\n",
    "Лучшие параметры: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 0.7}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7490\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6753\n",
    "F1-score: 0.5882\n",
    "ROC AUC: 0.7201\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.78 / 0.54\n",
    "Recall (класс 0 / класс 1): 0.69 / 0.65\n",
    "F1-score (класс 0 / класс 1): 0.73 / 0.59\n",
    "Анализ: XGBoost достиг ROC AUC 0.7201 на тестовой выборке, что является одним из лучших результатов. Accuracy (0.6753) и F1-score (0.5882) также сравнимы с другими моделями. Наблюдается тот же паттерн: высокая Precision для класса 0 (0.78) и низкая для класса 1 (0.54), что приводит к умеренному F1-score для класса 1.\n",
    "\n",
    "5. CatBoost Классификатор\n",
    "Лучшие параметры: {'classifier__depth': 6, 'classifier__iterations': 100, 'classifier__l2_leaf_reg': 3, 'classifier__learning_rate': 0.05}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7477\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6701\n",
    "F1-score: 0.5789\n",
    "ROC AUC: 0.7007\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.77 / 0.53\n",
    "Recall (класс 0 / класс 1): 0.69 / 0.64\n",
    "F1-score (класс 0 / класс 1): 0.73 / 0.58\n",
    "Анализ: CatBoost показал ROC AUC 0.7007 на тестовой выборке, что является хорошим результатом. Accuracy (0.6701) и F1-score (0.5789) схожи с другими моделями. Отчет по классификации подтверждает общую тенденцию: низкая Precision для класса 1 (0.53) при относительно неплохом Recall (0.64), что приводит к невысокому F1-score для положительного класса.\n",
    "\n",
    "6. Простая Нейронная Сеть\n",
    "Лучшие параметры: {'classifier__activation': 'relu', 'classifier__batch_size': 64, 'classifier__epochs': 50, 'classifier__hidden_layers': 2, 'classifier__learning_rate': 0.001, 'classifier__neurons': 32, 'classifier__optimizer': 'adam'}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7345\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6186\n",
    "F1-score: 0.5195\n",
    "ROC AUC: 0.6635\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.73 / 0.47\n",
    "Recall (класс 0 / класс 1): 0.64 / 0.58\n",
    "F1-score (класс 0 / класс 1): 0.68 / 0.52\n",
    "Анализ: Простая нейронная сеть показала самые низкие результаты по всем метрикам на тестовой выборке среди всех моделей, включая ROC AUC 0.6635. Accuracy (0.6186) и F1-score (0.5195) также являются самыми низкими. Особенно заметна очень низкая Precision для класса 1 (0.47), что делает её наименее подходящей для этой задачи.\n",
    "\n",
    "Общий вывод по классификации: SI > 8\n",
    "Задача классификации SI выше порогового значения 8 оказалась самой сложной из всех классификационных задач, что подтверждается относительно низкими значениями всех метрик. ROC AUC для большинства моделей находится в диапазоне 0.66–0.72, а F1-score для класса 1 (положительного класса, SI > 8) остаётся низким, в пределах 0.52–0.60. Это указывает на значительные трудности в точном определении образцов с высоким SI.\n",
    "\n",
    "Наилучшие результаты по ROC AUC на тестовой выборке показали Random Forest (0.7212) и XGBoost (0.7201), незначительно опережая Логистическую регрессию (0.6991) и LightGBM (0.7177). Однако, даже у лучших моделей, Precision для класса 1 остаётся на низком уровне (0.52-0.56), что приводит к большому количеству ложных положительных предсказаний.\n",
    "\n",
    "Несбалансированность классов (класс 0 значительно больше класса 1) вероятно, играет роль в сложности этой задачи. Хотя scale_pos_weight был использован, это не полностью решило проблему низкой Precision для класса 1.\n",
    "\n",
    "Вывод:\n",
    "Для задачи классификации \"превышает ли значение SI пороговое значение 8\" ни одна из моделей не достигла высокого уровня производительности. Random Forest и XGBoost показали себя несколько лучше остальных по ROC AUC, но общая эффективность остаётся умеренной. Для значительного улучшения качества классификации в этой задаче потребуются более глубокая работа с признаками, возможно, их расширение, а также более специализированные методы для работы с несбалансированными данными или дальнейшая тонкая настройка моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80b8f4-6bb4-4f63-bacf-179c86ff34b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92188e7b-bd6e-42ca-9df9-55e844b99de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "C:\\Users\\admin\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46840320-b6ca-4fa6-9407-1da0ddc5e6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68caf0bc-bc80-40f1-b5d2-caf1899994ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ec94f-4026-4c02-a516-3e6ad8ab1bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
