{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b044b6-d2dd-460f-9846-f618d8f0f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81572b6c-c850-4995-ba94-dd6cb211bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'данные для моделей.csv' успешно загружен.\n"
     ]
    }
   ],
   "source": [
    "# Чтение DataFrame\n",
    "df_models = pd.read_csv(\"данные для моделей.csv\")\n",
    "print(\"DataFrame 'данные для моделей.csv' успешно загружен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf59b79-68a3-4b32-afb7-4d3be5cdfd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Классификация: превышает ли значение SI медианное значение выборки ---\n",
      "Медианное значение log_SI: 0.5940\n",
      "Распределение классов для si_above_median:\n",
      "si_above_median\n",
      "0    484\n",
      "1    483\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Размер обучающей выборки (X_train_si_class): (773, 68)\n",
      "Размер тестовой выборки (X_test_si_class): (194, 68)\n",
      "Распределение классов в обучающей выборке:\n",
      "si_above_median\n",
      "0    0.500647\n",
      "1    0.499353\n",
      "Name: proportion, dtype: float64\n",
      "Распределение классов в тестовой выборке:\n",
      "si_above_median\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Классификация: превышает ли значение SI медианное значение выборки ---\")\n",
    "\n",
    "# 1. Определение целевой переменной для SI\n",
    "target_si_median_class = 'si_above_median' # Новая целевая колонка\n",
    "\n",
    "# Вычисляем медиану для 'log_SI'\n",
    "median_si = df_models['log_SI'].median()\n",
    "# Создаем бинарный столбец: 1, если log_SI > медианы, иначе 0\n",
    "df_models[target_si_median_class] = (df_models['log_SI'] > median_si).astype(int)\n",
    "\n",
    "print(f\"Медианное значение log_SI: {median_si:.4f}\")\n",
    "print(f\"Распределение классов для {target_si_median_class}:\\n{df_models[target_si_median_class].value_counts()}\")\n",
    "\n",
    "# Признаки (X) и целевая переменная (y)\n",
    "# Исключаем только исходные логарифмированные целевые переменные и только созданную бинарную целевую переменную для SI.\n",
    "X = df_models.drop(columns=['log_IC50, mM', 'log_CC50, mM', 'log_SI', target_si_median_class])\n",
    "y = df_models[target_si_median_class]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_si_class, X_test_si_class, y_train_si_class, y_test_si_class = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y # stratify=y для сохранения пропорций классов\n",
    ")\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки (X_train_si_class): {X_train_si_class.shape}\")\n",
    "print(f\"Размер тестовой выборки (X_test_si_class): {X_test_si_class.shape}\")\n",
    "print(f\"Распределение классов в обучающей выборке:\\n{y_train_si_class.value_counts(normalize=True)}\")\n",
    "print(f\"Распределение классов в тестовой выборке:\\n{y_test_si_class.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3377e44a-6a65-4ab9-a995-57607e28e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики для GridSearchCV (остаются теми же)\n",
    "scoring_metrics_class = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': 'f1',\n",
    "    'ROC_AUC': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7faf9853-17aa-4749-80fb-d439bb6a211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Логистическая Регрессия для SI (классификация) =====\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Лучшие параметры для Логистической Регрессии: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.6741209007442773\n",
      "\n",
      "Метрики на тестовой выборке (Логистическая Регрессия):\n",
      "Accuracy: 0.6701\n",
      "F1-score: 0.6484\n",
      "ROC AUC: 0.7272\n",
      "\n",
      "Classification Report (Логистическая Регрессия):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        97\n",
      "           1       0.69      0.61      0.65        97\n",
      "\n",
      "    accuracy                           0.67       194\n",
      "   macro avg       0.67      0.67      0.67       194\n",
      "weighted avg       0.67      0.67      0.67       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 1: Логистическая Регрессия \n",
    "print(\"\\n===== Логистическая Регрессия для SI (классификация) =====\")\n",
    "pipeline_lr_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear'))\n",
    "])\n",
    "\n",
    "param_grid_lr_class_si = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search_lr_class_si = GridSearchCV(\n",
    "    pipeline_lr_class_si,\n",
    "    param_grid_lr_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lr_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для Логистической Регрессии:\", grid_search_lr_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_lr_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lr_class_si = grid_search_lr_class_si.predict(X_test_si_class)\n",
    "y_proba_lr_class_si = grid_search_lr_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_lr_class_si = accuracy_score(y_test_si_class, y_pred_lr_class_si)\n",
    "f1_lr_class_si = f1_score(y_test_si_class, y_pred_lr_class_si)\n",
    "roc_auc_lr_class_si = roc_auc_score(y_test_si_class, y_proba_lr_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Логистическая Регрессия):\")\n",
    "print(f\"Accuracy: {accuracy_lr_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_lr_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lr_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (Логистическая Регрессия):\")\n",
    "print(classification_report(y_test_si_class, y_pred_lr_class_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173fb0ed-2b71-434d-aa9f-2b982f7ab5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random Forest Классификатор для SI (классификация) =====\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Лучшие параметры для Random Forest: {'classifier__max_features': 1.0, 'classifier__min_samples_leaf': 5, 'classifier__n_estimators': 200}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7222195553364384\n",
      "\n",
      "Метрики на тестовой выборке (Random Forest):\n",
      "Accuracy: 0.6237\n",
      "F1-score: 0.6138\n",
      "ROC AUC: 0.6771\n",
      "\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63        97\n",
      "           1       0.63      0.60      0.61        97\n",
      "\n",
      "    accuracy                           0.62       194\n",
      "   macro avg       0.62      0.62      0.62       194\n",
      "weighted avg       0.62      0.62      0.62       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Модель 2: Random Forest Классификатор \n",
    "print(\"\\n===== Random Forest Классификатор для SI (классификация) =====\")\n",
    "pipeline_rf_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf_class_si = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_features': [0.6, 0.8, 1.0],\n",
    "    'classifier__min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "grid_search_rf_class_si = GridSearchCV(\n",
    "    pipeline_rf_class_si,\n",
    "    param_grid_rf_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для Random Forest:\", grid_search_rf_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_rf_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_rf_class_si = grid_search_rf_class_si.predict(X_test_si_class)\n",
    "y_proba_rf_class_si = grid_search_rf_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_rf_class_si = accuracy_score(y_test_si_class, y_pred_rf_class_si)\n",
    "f1_rf_class_si = f1_score(y_test_si_class, y_pred_rf_class_si)\n",
    "roc_auc_rf_class_si = roc_auc_score(y_test_si_class, y_proba_rf_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Random Forest):\")\n",
    "print(f\"Accuracy: {accuracy_rf_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_rf_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_rf_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test_si_class, y_pred_rf_class_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361c12ff-b5fa-4469-8e6a-c06e8655e703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LightGBM Классификатор для SI (классификация) =====\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Лучшие параметры для LightGBM: {'classifier__learning_rate': 0.01, 'classifier__n_estimators': 100, 'classifier__num_leaves': 20, 'classifier__reg_alpha': 0.1, 'classifier__reg_lambda': 0.5}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7165388723830282\n",
      "\n",
      "Метрики на тестовой выборке (LightGBM):\n",
      "Accuracy: 0.6598\n",
      "F1-score: 0.6633\n",
      "ROC AUC: 0.6981\n",
      "\n",
      "Classification Report (LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66        97\n",
      "           1       0.66      0.67      0.66        97\n",
      "\n",
      "    accuracy                           0.66       194\n",
      "   macro avg       0.66      0.66      0.66       194\n",
      "weighted avg       0.66      0.66      0.66       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 3: LightGBM Классификатор \n",
    "print(\"\\n===== LightGBM Классификатор для SI (классификация) =====\")\n",
    "pipeline_lgbm_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LGBMClassifier(random_state=42, verbose=-1))\n",
    "])\n",
    "\n",
    "param_grid_lgbm_class_si = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__num_leaves': [20, 31],\n",
    "    'classifier__reg_alpha': [0.1, 0.5],\n",
    "    'classifier__reg_lambda': [0.1, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_lgbm_class_si = GridSearchCV(\n",
    "    pipeline_lgbm_class_si,\n",
    "    param_grid_lgbm_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lgbm_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для LightGBM:\", grid_search_lgbm_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_lgbm_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lgbm_class_si = grid_search_lgbm_class_si.predict(X_test_si_class)\n",
    "y_proba_lgbm_class_si = grid_search_lgbm_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_lgbm_class_si = accuracy_score(y_test_si_class, y_pred_lgbm_class_si)\n",
    "f1_lgbm_class_si = f1_score(y_test_si_class, y_pred_lgbm_class_si)\n",
    "roc_auc_lgbm_class_si = roc_auc_score(y_test_si_class, y_proba_lgbm_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (LightGBM):\")\n",
    "print(f\"Accuracy: {accuracy_lgbm_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_lgbm_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lgbm_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (LightGBM):\")\n",
    "print(classification_report(y_test_si_class, y_pred_lgbm_class_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a83d8c-1f85-4254-b994-692dceeb0f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== XGBoost Классификатор для SI (классификация) =====\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:30:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для XGBoost: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 0.7}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7198414139972582\n",
      "\n",
      "Метрики на тестовой выборке (XGBoost):\n",
      "Accuracy: 0.6649\n",
      "F1-score: 0.6409\n",
      "ROC AUC: 0.6947\n",
      "\n",
      "Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        97\n",
      "           1       0.69      0.60      0.64        97\n",
      "\n",
      "    accuracy                           0.66       194\n",
      "   macro avg       0.67      0.66      0.66       194\n",
      "weighted avg       0.67      0.66      0.66       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 4: XGBoost Классификатор\n",
    "print(\"\\n===== XGBoost Классификатор для SI (классификация) =====\")\n",
    "pipeline_xgb_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "param_grid_xgb_class_si = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__subsample': [0.7, 1.0],\n",
    "    'classifier__colsample_bytree': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgb_class_si = GridSearchCV(\n",
    "    pipeline_xgb_class_si,\n",
    "    param_grid_xgb_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_xgb_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для XGBoost:\", grid_search_xgb_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_xgb_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_xgb_class_si = grid_search_xgb_class_si.predict(X_test_si_class)\n",
    "y_proba_xgb_class_si = grid_search_xgb_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_xgb_class_si = accuracy_score(y_test_si_class, y_pred_xgb_class_si)\n",
    "f1_xgb_class_si = f1_score(y_test_si_class, y_pred_xgb_class_si)\n",
    "roc_auc_xgb_class_si = roc_auc_score(y_test_si_class, y_proba_xgb_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (XGBoost):\")\n",
    "print(f\"Accuracy: {accuracy_xgb_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_xgb_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_xgb_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (XGBoost):\")\n",
    "print(classification_report(y_test_si_class, y_pred_xgb_class_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e0f39a-965e-4e4b-bc55-7042ac4170c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CatBoost Классификатор для SI (классификация) =====\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Лучшие параметры для CatBoost: {'classifier__depth': 6, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 3, 'classifier__learning_rate': 0.01}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.7161797077381493\n",
      "\n",
      "Метрики на тестовой выборке (CatBoost):\n",
      "Accuracy: 0.6546\n",
      "F1-score: 0.6257\n",
      "ROC AUC: 0.7152\n",
      "\n",
      "Classification Report (CatBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68        97\n",
      "           1       0.68      0.58      0.63        97\n",
      "\n",
      "    accuracy                           0.65       194\n",
      "   macro avg       0.66      0.65      0.65       194\n",
      "weighted avg       0.66      0.65      0.65       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 5: CatBoost Классификатор\n",
    "print(\"\\n===== CatBoost Классификатор для SI (классификация) =====\")\n",
    "pipeline_cat_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', CatBoostClassifier(random_state=42, verbose=0))\n",
    "])\n",
    "\n",
    "param_grid_cat_class_si = {\n",
    "    'classifier__iterations': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__depth': [4, 6],\n",
    "    'classifier__l2_leaf_reg': [1, 3]\n",
    "}\n",
    "\n",
    "grid_search_cat_class_si = GridSearchCV(\n",
    "    pipeline_cat_class_si,\n",
    "    param_grid_cat_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_cat_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для CatBoost:\", grid_search_cat_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_cat_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_cat_class_si = grid_search_cat_class_si.predict(X_test_si_class)\n",
    "y_proba_cat_class_si = grid_search_cat_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_cat_class_si = accuracy_score(y_test_si_class, y_pred_cat_class_si)\n",
    "f1_cat_class_si = f1_score(y_test_si_class, y_pred_cat_class_si)\n",
    "roc_auc_cat_class_si = roc_auc_score(y_test_si_class, y_proba_cat_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (CatBoost):\")\n",
    "print(f\"Accuracy: {accuracy_cat_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_cat_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_cat_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (CatBoost):\")\n",
    "print(classification_report(y_test_si_class, y_pred_cat_class_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc2f1a8-231b-4164-9728-bbb57e313dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Простая Нейронная Сеть для SI (классификация) =====\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для Нейронной Сети: {'classifier__activation': 'relu', 'classifier__batch_size': 64, 'classifier__epochs': 50, 'classifier__hidden_layers': 1, 'classifier__learning_rate': 0.001, 'classifier__neurons': 32, 'classifier__optimizer': 'adam'}\n",
      "Лучший ROC_AUC на кросс-валидации: 0.6953302617280612\n",
      "\n",
      "Метрики на тестовой выборке (Нейронная Сеть):\n",
      "Accuracy: 0.6443\n",
      "F1-score: 0.6387\n",
      "ROC AUC: 0.7062\n",
      "\n",
      "Classification Report (Нейронная Сеть):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65        97\n",
      "           1       0.65      0.63      0.64        97\n",
      "\n",
      "    accuracy                           0.64       194\n",
      "   macro avg       0.64      0.64      0.64       194\n",
      "weighted avg       0.64      0.64      0.64       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Модель 6: Простая Нейронная Сеть (Keras Sequential)\n",
    "print(\"\\n===== Простая Нейронная Сеть для SI (классификация) =====\")\n",
    "\n",
    "# Функция для создания Keras-модели \n",
    "def build_nn_model_class(meta, hidden_layers=1, neurons=32, activation='relu',\n",
    "                         optimizer='adam', learning_rate=0.001):\n",
    "    n_features = meta[\"n_features_in_\"]\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(L.Input(shape=(n_features,)))\n",
    "    \n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(L.Dense(neurons, activation=activation))\n",
    "        \n",
    "    model.add(L.Dense(1, activation='sigmoid')) # Sigmoid для бинарной классификации\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline_nn_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KerasClassifier(\n",
    "        model=build_nn_model_class,\n",
    "        hidden_layers=1,\n",
    "        neurons=32,\n",
    "        activation='relu',\n",
    "        optimizer='adam',\n",
    "        learning_rate=0.001,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        loss='binary_crossentropy' # Лосс для бинарной классификации\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid_nn_class_si = {\n",
    "    'classifier__hidden_layers': [1, 2],\n",
    "    'classifier__neurons': [32, 64],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__optimizer': ['adam'],\n",
    "    'classifier__learning_rate': [0.001, 0.01],\n",
    "    'classifier__batch_size': [32, 64],\n",
    "    'classifier__epochs': [50, 100]\n",
    "}\n",
    "\n",
    "grid_search_nn_class_si = GridSearchCV(\n",
    "    pipeline_nn_class_si,\n",
    "    param_grid_nn_class_si,\n",
    "    cv=3, # Уменьшаем CV для скорости NN\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_nn_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для Нейронной Сети:\", grid_search_nn_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_nn_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_nn_class_si = grid_search_nn_class_si.predict(X_test_si_class)\n",
    "y_proba_nn_class_si = grid_search_nn_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_nn_class_si = accuracy_score(y_test_si_class, y_pred_nn_class_si)\n",
    "f1_nn_class_si = f1_score(y_test_si_class, y_pred_nn_class_si)\n",
    "roc_auc_nn_class_si = roc_auc_score(y_test_si_class, y_proba_nn_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Нейронная Сеть):\")\n",
    "print(f\"Accuracy: {accuracy_nn_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_nn_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_nn_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (Нейронная Сеть):\")\n",
    "print(classification_report(y_test_si_class, y_pred_nn_class_si))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfdebd-a79d-4ceb-a333-27af14416fce",
   "metadata": {},
   "source": [
    "Медианное значение log_SI составляет 0.5940. Распределение классов в целевой переменной si_above_median хорошо сбалансировано (484 для класса 0 и 483 для класса 1). Размеры обучающей и тестовой выборок, а также распределение классов в них, также являются сбалансированными.\n",
    "\n",
    "1. Логистическая Регрессия\n",
    "Лучшие параметры: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
    "Лучший ROC AUC на кросс-валидации: 0.6741\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6701\n",
    "F1-score: 0.6484\n",
    "ROC AUC: 0.7272\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.65 / 0.69\n",
    "Recall (класс 0 / класс 1): 0.73 / 0.61\n",
    "F1-score (класс 0 / класс 1): 0.69 / 0.65\n",
    "Модель логистической регрессии показала наиболее высокий ROC AUC (0.7272) среди всех протестированных моделей на тестовой выборке. Accuracy составила 0.6701, а F1-score — 0.6484. В отчете по классификации заметно, что для класса 0 (значение SI ниже медианы) Recall выше (0.73), чем для класса 1 (0.61), в то время как Precision для класса 1 (0.69) выше, чем для класса 0 (0.65). Это указывает на лучшую способность модели выявлять образцы, не превышающие медиану, но с некоторым количеством ложных срабатываний для класса 1.\n",
    "\n",
    "2. Random Forest Классификатор\n",
    "Лучшие параметры: {'classifier__max_features': 1.0, 'classifier__min_samples_leaf': 5, 'classifier__n_estimators': 200}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7222\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6237\n",
    "F1-score: 0.6138\n",
    "ROC AUC: 0.6771\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.62 / 0.63\n",
    "Recall (класс 0 / класс 1): 0.65 / 0.60\n",
    "F1-score (класс 0 / класс 1): 0.63 / 0.61\n",
    "Модель Random Forest продемонстрировала ROC AUC 0.6771 на тестовой выборке, что является одним из самых низких показателей в этом сравнении. Accuracy составила 0.6237, F1-score — 0.6138. Производительность модели на тестовой выборке заметно ниже, чем на кросс-валидации, что может указывать на некоторое переобучение. Precision и Recall для обоих классов относительно сбалансированы, но находятся на низком уровне.\n",
    "\n",
    "3. LightGBM Классификатор\n",
    "Лучшие параметры: {'classifier__learning_rate': 0.01, 'classifier__n_estimators': 100, 'classifier__num_leaves': 20, 'classifier__reg_alpha': 0.1, 'classifier__reg_lambda': 0.5}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7165\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6598\n",
    "F1-score: 0.6633\n",
    "ROC AUC: 0.6981\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.66 / 0.66\n",
    "Recall (класс 0 / класс 1): 0.65 / 0.67\n",
    "F1-score (класс 0 / класс 1): 0.66 / 0.66\n",
    "LightGBM показал ROC AUC 0.6981 на тестовой выборке. Accuracy и F1-score также были средними (0.6598 и 0.6633 соответственно). Precision и Recall для обоих классов очень хорошо сбалансированы (около 0.66-0.67), что указывает на равномерную производительность модели для обоих классов, но общий уровень метрик остается невысоким.\n",
    "\n",
    "4. XGBoost Классификатор\n",
    "Лучшие параметры: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 0.7}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7198\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6649\n",
    "F1-score: 0.6409\n",
    "ROC AUC: 0.6947\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.65 / 0.69\n",
    "Recall (класс 0 / класс 1): 0.73 / 0.60\n",
    "F1-score (класс 0 / класс 1): 0.69 / 0.64\n",
    "XGBoost продемонстрировал ROC AUC 0.6947 на тестовой выборке. Accuracy (0.6649) и F1-score (0.6409) также находятся на среднем уровне. Отчет по классификации выявил аналогичную тенденцию, как и у логистической регрессии: более высокий Recall для класса 0 (0.73) и более высокий Precision для класса 1 (0.69), что указывает на склонность модели к идентификации образцов, не превышающих медиану.\n",
    "\n",
    "5. CatBoost Классификатор\n",
    "Лучшие параметры: {'classifier__depth': 6, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 3, 'classifier__learning_rate': 0.01}\n",
    "Лучший ROC AUC на кросс-валидации: 0.7162\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6546\n",
    "F1-score: 0.6257\n",
    "ROC AUC: 0.7152\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.63 / 0.68\n",
    "Recall (класс 0 / класс 1): 0.73 / 0.58\n",
    "F1-score (класс 0 / класс 1): 0.68 / 0.63\n",
    "CatBoost показал ROC AUC 0.7152 на тестовой выборке. Accuracy (0.6546) и F1-score (0.6257) оказались средними. Модель, как и Логистическая регрессия и XGBoost, демонстрирует смещение в сторону лучшего Recall для класса 0 (0.73) и более высокой Precision для класса 1 (0.68), при этом Recall для класса 1 является самым низким среди всех моделей (0.58).\n",
    "\n",
    "6. Простая Нейронная Сеть\n",
    "Лучшие параметры: {'classifier__activation': 'relu', 'classifier__batch_size': 64, 'classifier__epochs': 50, 'classifier__hidden_layers': 1, 'classifier__learning_rate': 0.001, 'classifier__neurons': 32, 'classifier__optimizer': 'adam'}\n",
    "Лучший ROC AUC на кросс-валидации: 0.6953\n",
    "Метрики на тестовой выборке:\n",
    "Accuracy: 0.6443\n",
    "F1-score: 0.6387\n",
    "ROC AUC: 0.7062\n",
    "Classification Report:\n",
    "Precision (класс 0 / класс 1): 0.64 / 0.65\n",
    "Recall (класс 0 / класс 1): 0.66 / 0.63\n",
    "F1-score (класс 0 / класс 1): 0.65 / 0.64\n",
    "Простая нейронная сеть продемонстрировала ROC AUC 0.7062 на тестовой выборке. Accuracy (0.6443) и F1-score (0.6387) также были средними. Precision и Recall для обоих классов относительно сбалансированы, но на невысоком уровне.\n",
    "\n",
    "### Общий вывод по классификации: SI выше медианы\n",
    "Результаты классификации для SI выше медианы оказались значительно ниже, чем для IC50 и CC50. ROC AUC для большинства моделей находится в диапазоне 0.67–0.73, а Accuracy и F1-score не превышают 0.67. Это согласуется с ранее полученными слабыми результатами регрессии для log_SI и указывает на общую сложность прогнозирования этого показателя на основе текущего набора признаков. Наилучшие результаты по ROC AUC на тестовой выборке показала Логистическая Регрессия (0.7272), что является неожиданностью, так как для регрессии она была самой слабой моделью. Среди остальных моделей, LightGBM, XGBoost, CatBoost и Нейронная сеть показали ROC AUC в диапазоне 0.69-0.71, а Random Forest — самый низкий (0.6771).\n",
    "\n",
    "Переобучение/Недообучение:\n",
    "У некоторых моделей, таких как Random Forest, наблюдается заметное падение ROC AUC на тестовой выборке по сравнению с кросс-валидацией (например, у Random Forest с 0.7222 до 0.6771), что может указывать на склонность к переобучению на тренировочных данных.\n",
    "Логистическая Регрессия показала себя неожиданно лучше остальных моделей по ROC AUC на тестовой выборке, хотя общий уровень производительности всех моделей остаётся умеренным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bb4c2-0995-4b50-8927-4480298c9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
