{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ae5d7-3d2c-4d0e-9ec1-846a69a5d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Предполагаем, что df_models уже загружен и содержит необходимые столбцы.\n",
    "# Если df_models не определен, необходимо его загрузить, например:\n",
    "# df_models = pd.read_csv('your_dataset.csv')\n",
    "# Убедитесь, что колонки 'log_IC50, mM', 'log_CC50, mM', 'log_SI' существуют.\n",
    "\n",
    "print(\"\\n--- Классификация: превышает ли значение SI медианное значение выборки ---\")\n",
    "\n",
    "# 1. Определение целевой переменной для SI\n",
    "target_si_median_class = 'si_above_median' # Новая целевая колонка\n",
    "\n",
    "# Вычисляем медиану для 'log_SI'\n",
    "median_si = df_models['log_SI'].median()\n",
    "# Создаем бинарный столбец: 1, если log_SI > медианы, иначе 0\n",
    "df_models[target_si_median_class] = (df_models['log_SI'] > median_si).astype(int)\n",
    "\n",
    "print(f\"Медианное значение log_SI: {median_si:.4f}\")\n",
    "print(f\"Распределение классов для {target_si_median_class}:\\n{df_models[target_si_median_class].value_counts()}\")\n",
    "\n",
    "# Признаки (X) и целевая переменная (y)\n",
    "# Исключаем только исходные логарифмированные целевые переменные и только созданную бинарную целевую переменную для SI.\n",
    "X = df_models.drop(columns=['log_IC50, mM', 'log_CC50, mM', 'log_SI', target_si_median_class])\n",
    "y = df_models[target_si_median_class]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_si_class, X_test_si_class, y_train_si_class, y_test_si_class = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y # stratify=y для сохранения пропорций классов\n",
    ")\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки (X_train_si_class): {X_train_si_class.shape}\")\n",
    "print(f\"Размер тестовой выборки (X_test_si_class): {X_test_si_class.shape}\")\n",
    "print(f\"Распределение классов в обучающей выборке:\\n{y_train_si_class.value_counts(normalize=True)}\")\n",
    "print(f\"Распределение классов в тестовой выборке:\\n{y_test_si_class.value_counts(normalize=True)}\")\n",
    "\n",
    "# Метрики для GridSearchCV (остаются теми же)\n",
    "scoring_metrics_class = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': 'f1',\n",
    "    'ROC_AUC': 'roc_auc'\n",
    "}\n",
    "\n",
    "# --- Модель 1: Логистическая Регрессия ---\n",
    "print(\"\\n===== Логистическая Регрессия для SI (классификация) =====\")\n",
    "pipeline_lr_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear'))\n",
    "])\n",
    "\n",
    "param_grid_lr_class_si = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search_lr_class_si = GridSearchCV(\n",
    "    pipeline_lr_class_si,\n",
    "    param_grid_lr_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lr_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для Логистической Регрессии:\", grid_search_lr_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_lr_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lr_class_si = grid_search_lr_class_si.predict(X_test_si_class)\n",
    "y_proba_lr_class_si = grid_search_lr_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_lr_class_si = accuracy_score(y_test_si_class, y_pred_lr_class_si)\n",
    "f1_lr_class_si = f1_score(y_test_si_class, y_pred_lr_class_si)\n",
    "roc_auc_lr_class_si = roc_auc_score(y_test_si_class, y_proba_lr_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Логистическая Регрессия):\")\n",
    "print(f\"Accuracy: {accuracy_lr_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_lr_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lr_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (Логистическая Регрессия):\")\n",
    "print(classification_report(y_test_si_class, y_pred_lr_class_si))\n",
    "\n",
    "\n",
    "# --- Модель 2: Random Forest Классификатор ---\n",
    "print(\"\\n===== Random Forest Классификатор для SI (классификация) =====\")\n",
    "pipeline_rf_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf_class_si = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_features': [0.6, 0.8, 1.0],\n",
    "    'classifier__min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "grid_search_rf_class_si = GridSearchCV(\n",
    "    pipeline_rf_class_si,\n",
    "    param_grid_rf_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для Random Forest:\", grid_search_rf_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_rf_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_rf_class_si = grid_search_rf_class_si.predict(X_test_si_class)\n",
    "y_proba_rf_class_si = grid_search_rf_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_rf_class_si = accuracy_score(y_test_si_class, y_pred_rf_class_si)\n",
    "f1_rf_class_si = f1_score(y_test_si_class, y_pred_rf_class_si)\n",
    "roc_auc_rf_class_si = roc_auc_score(y_test_si_class, y_proba_rf_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Random Forest):\")\n",
    "print(f\"Accuracy: {accuracy_rf_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_rf_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_rf_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test_si_class, y_pred_rf_class_si))\n",
    "\n",
    "\n",
    "# --- Модель 3: LightGBM Классификатор ---\n",
    "print(\"\\n===== LightGBM Классификатор для SI (классификация) =====\")\n",
    "pipeline_lgbm_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LGBMClassifier(random_state=42, verbose=-1))\n",
    "])\n",
    "\n",
    "param_grid_lgbm_class_si = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__num_leaves': [20, 31],\n",
    "    'classifier__reg_alpha': [0.1, 0.5],\n",
    "    'classifier__reg_lambda': [0.1, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_lgbm_class_si = GridSearchCV(\n",
    "    pipeline_lgbm_class_si,\n",
    "    param_grid_lgbm_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lgbm_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для LightGBM:\", grid_search_lgbm_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_lgbm_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lgbm_class_si = grid_search_lgbm_class_si.predict(X_test_si_class)\n",
    "y_proba_lgbm_class_si = grid_search_lgbm_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_lgbm_class_si = accuracy_score(y_test_si_class, y_pred_lgbm_class_si)\n",
    "f1_lgbm_class_si = f1_score(y_test_si_class, y_pred_lgbm_class_si)\n",
    "roc_auc_lgbm_class_si = roc_auc_score(y_test_si_class, y_proba_lgbm_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (LightGBM):\")\n",
    "print(f\"Accuracy: {accuracy_lgbm_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_lgbm_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lgbm_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (LightGBM):\")\n",
    "print(classification_report(y_test_si_class, y_pred_lgbm_class_si))\n",
    "\n",
    "\n",
    "# --- Модель 4: XGBoost Классификатор ---\n",
    "print(\"\\n===== XGBoost Классификатор для SI (классификация) =====\")\n",
    "pipeline_xgb_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "param_grid_xgb_class_si = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__subsample': [0.7, 1.0],\n",
    "    'classifier__colsample_bytree': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgb_class_si = GridSearchCV(\n",
    "    pipeline_xgb_class_si,\n",
    "    param_grid_xgb_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_xgb_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для XGBoost:\", grid_search_xgb_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_xgb_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_xgb_class_si = grid_search_xgb_class_si.predict(X_test_si_class)\n",
    "y_proba_xgb_class_si = grid_search_xgb_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_xgb_class_si = accuracy_score(y_test_si_class, y_pred_xgb_class_si)\n",
    "f1_xgb_class_si = f1_score(y_test_si_class, y_pred_xgb_class_si)\n",
    "roc_auc_xgb_class_si = roc_auc_score(y_test_si_class, y_proba_xgb_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (XGBoost):\")\n",
    "print(f\"Accuracy: {accuracy_xgb_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_xgb_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_xgb_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (XGBoost):\")\n",
    "print(classification_report(y_test_si_class, y_pred_xgb_class_si))\n",
    "\n",
    "\n",
    "# --- Модель 5: CatBoost Классификатор ---\n",
    "print(\"\\n===== CatBoost Классификатор для SI (классификация) =====\")\n",
    "pipeline_cat_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', CatBoostClassifier(random_state=42, verbose=0))\n",
    "])\n",
    "\n",
    "param_grid_cat_class_si = {\n",
    "    'classifier__iterations': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__depth': [4, 6],\n",
    "    'classifier__l2_leaf_reg': [1, 3]\n",
    "}\n",
    "\n",
    "grid_search_cat_class_si = GridSearchCV(\n",
    "    pipeline_cat_class_si,\n",
    "    param_grid_cat_class_si,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_cat_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для CatBoost:\", grid_search_cat_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_cat_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_cat_class_si = grid_search_cat_class_si.predict(X_test_si_class)\n",
    "y_proba_cat_class_si = grid_search_cat_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_cat_class_si = accuracy_score(y_test_si_class, y_pred_cat_class_si)\n",
    "f1_cat_class_si = f1_score(y_test_si_class, y_pred_cat_class_si)\n",
    "roc_auc_cat_class_si = roc_auc_score(y_test_si_class, y_proba_cat_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (CatBoost):\")\n",
    "print(f\"Accuracy: {accuracy_cat_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_cat_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_cat_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (CatBoost):\")\n",
    "print(classification_report(y_test_si_class, y_pred_cat_class_si))\n",
    "\n",
    "\n",
    "# --- Модель 6: Простая Нейронная Сеть (Keras Sequential) ---\n",
    "print(\"\\n===== Простая Нейронная Сеть для SI (классификация) =====\")\n",
    "\n",
    "# Функция для создания Keras-модели (используем ту же, что и раньше)\n",
    "def build_nn_model_class(meta, hidden_layers=1, neurons=32, activation='relu',\n",
    "                         optimizer='adam', learning_rate=0.001):\n",
    "    n_features = meta[\"n_features_in_\"]\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(L.Input(shape=(n_features,)))\n",
    "    \n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(L.Dense(neurons, activation=activation))\n",
    "        \n",
    "    model.add(L.Dense(1, activation='sigmoid')) # Sigmoid для бинарной классификации\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline_nn_class_si = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KerasClassifier(\n",
    "        model=build_nn_model_class,\n",
    "        hidden_layers=1,\n",
    "        neurons=32,\n",
    "        activation='relu',\n",
    "        optimizer='adam',\n",
    "        learning_rate=0.001,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        loss='binary_crossentropy' # Лосс для бинарной классификации\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid_nn_class_si = {\n",
    "    'classifier__hidden_layers': [1, 2],\n",
    "    'classifier__neurons': [32, 64],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__optimizer': ['adam'],\n",
    "    'classifier__learning_rate': [0.001, 0.01],\n",
    "    'classifier__batch_size': [32, 64],\n",
    "    'classifier__epochs': [50, 100]\n",
    "}\n",
    "\n",
    "grid_search_nn_class_si = GridSearchCV(\n",
    "    pipeline_nn_class_si,\n",
    "    param_grid_nn_class_si,\n",
    "    cv=3, # Уменьшаем CV для скорости NN\n",
    "    scoring=scoring_metrics_class,\n",
    "    refit='ROC_AUC',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_nn_class_si.fit(X_train_si_class, y_train_si_class)\n",
    "\n",
    "print(\"Лучшие параметры для Нейронной Сети:\", grid_search_nn_class_si.best_params_)\n",
    "print(\"Лучший ROC_AUC на кросс-валидации:\", grid_search_nn_class_si.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_nn_class_si = grid_search_nn_class_si.predict(X_test_si_class)\n",
    "y_proba_nn_class_si = grid_search_nn_class_si.predict_proba(X_test_si_class)[:, 1]\n",
    "\n",
    "accuracy_nn_class_si = accuracy_score(y_test_si_class, y_pred_nn_class_si)\n",
    "f1_nn_class_si = f1_score(y_test_si_class, y_pred_nn_class_si)\n",
    "roc_auc_nn_class_si = roc_auc_score(y_test_si_class, y_proba_nn_class_si)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Нейронная Сеть):\")\n",
    "print(f\"Accuracy: {accuracy_nn_class_si:.4f}\")\n",
    "print(f\"F1-score: {f1_nn_class_si:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_nn_class_si:.4f}\")\n",
    "print(\"\\nClassification Report (Нейронная Сеть):\")\n",
    "print(classification_report(y_test_si_class, y_pred_nn_class_si))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
