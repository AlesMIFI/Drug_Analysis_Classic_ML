{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae157b3-880c-47fd-9901-7a756fef7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from scikeras.wrappers import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f95c5c-81ef-491f-b96f-54e45559ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'данные для моделей.csv' успешно загружен.\n"
     ]
    }
   ],
   "source": [
    "# Чтение DataFrame\n",
    "df_models = pd.read_csv(\"данные для моделей.csv\")\n",
    "print(\"DataFrame 'данные для моделей.csv' успешно загружен.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276b87b4-6d1a-47b2-9b96-193e385485c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Подготовка данных для CC50 ---\n",
      "Размер обучающей выборки (X_train_cc50): (773, 68)\n",
      "Размер тестовой выборки (X_test_cc50): (194, 68)\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для CC50\n",
    "# Целевая переменная для CC50\n",
    "target_cc50 = 'log_CC50, mM'\n",
    "\n",
    "# Признаки (X) и целевая переменная (y)\n",
    "# Исключаем другие целевые переменные из признаков\n",
    "X = df_models.drop(columns=['log_IC50, mM', 'log_CC50, mM', 'log_SI'])\n",
    "y = df_models[target_cc50]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "# random_state для воспроизводимости\n",
    "X_train_cc50, X_test_cc50, y_train_cc50, y_test_cc50 = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Подготовка данных для CC50 ---\")\n",
    "print(f\"Размер обучающей выборки (X_train_cc50): {X_train_cc50.shape}\")\n",
    "print(f\"Размер тестовой выборки (X_test_cc50): {X_test_cc50.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ae6a80-22e9-4b37-8cb5-b94af19dd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка Pipeline и GridSearchCV\n",
    "\n",
    "# Метрики для GridSearchCV. 'neg_' - максимизировать метрику,\n",
    "scoring_metrics = {\n",
    "    'MSE': 'neg_mean_squared_error',\n",
    "    'R2': 'r2',\n",
    "    'MAE': 'neg_mean_absolute_error'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414c631e-e62b-4b50-9b35-ac754df548de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Линейная Регрессия для CC50 =====\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Лучшие параметры для Линейной Регрессии: {}\n",
      "Лучший R2 на кросс-валидации: 0.258081036545079\n",
      "\n",
      "Метрики на тестовой выборке (Линейная Регрессия):\n",
      "MSE: 0.3862\n",
      "MAE: 0.4699\n",
      "R2: 0.2913\n"
     ]
    }
   ],
   "source": [
    "# Модель 1: Линейная Регрессия \n",
    "print(\"\\n===== Линейная Регрессия для CC50 =====\")\n",
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "param_grid_lr = {} # Для LinearRegression нет гиперпараметров для настройки в данном случае\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    pipeline_lr,\n",
    "    param_grid_lr,\n",
    "    cv=5, # 5-кратная кросс-валидация\n",
    "    scoring=scoring_metrics,\n",
    "    refit='R2', # Оптимизировать по R2\n",
    "    n_jobs=-1, # Использовать все доступные ядра\n",
    "    verbose=1 # Выводить прогресс\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(X_train_cc50, y_train_cc50)\n",
    "\n",
    "print(\"Лучшие параметры для Линейной Регрессии:\", grid_search_lr.best_params_)\n",
    "print(\"Лучший R2 на кросс-валидации:\", grid_search_lr.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lr = grid_search_lr.predict(X_test_cc50)\n",
    "mse_lr = mean_squared_error(y_test_cc50, y_pred_lr)\n",
    "r2_lr = r2_score(y_test_cc50, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test_cc50, y_pred_lr)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Линейная Регрессия):\")\n",
    "print(f\"MSE: {mse_lr:.4f}\")\n",
    "print(f\"MAE: {mae_lr:.4f}\")\n",
    "print(f\"R2: {r2_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9771db8-cb90-4aec-8f5e-88b09eacca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random Forest Регрессор для CC50 =====\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Лучшие параметры для Random Forest: {'regressor__max_features': 0.8, 'regressor__min_samples_leaf': 5, 'regressor__n_estimators': 200}\n",
      "Лучший R2 на кросс-валидации: 0.4011023361332707\n",
      "\n",
      "Метрики на тестовой выборке (Random Forest):\n",
      "MSE: 0.3069\n",
      "MAE: 0.4095\n",
      "R2: 0.4369\n"
     ]
    }
   ],
   "source": [
    "# Модель 2: Random Forest Регрессор \n",
    "print(\"\\n===== Random Forest Регрессор для CC50 =====\")\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Гиперпараметры для настройки Random Forest\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_features': [0.6, 0.8, 1.0],\n",
    "    'regressor__min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    pipeline_rf,\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='R2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train_cc50, y_train_cc50)\n",
    "\n",
    "print(\"Лучшие параметры для Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Лучший R2 на кросс-валидации:\", grid_search_rf.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_rf = grid_search_rf.predict(X_test_cc50)\n",
    "mse_rf = mean_squared_error(y_test_cc50, y_pred_rf)\n",
    "r2_rf = r2_score(y_test_cc50, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test_cc50, y_pred_rf)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Random Forest):\")\n",
    "print(f\"MSE: {mse_rf:.4f}\")\n",
    "print(f\"MAE: {mae_rf:.4f}\")\n",
    "print(f\"R2: {r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7579a105-0164-4dcc-95b3-2c8d971a5432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LightGBM Регрессор для CC50 =====\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9262\n",
      "[LightGBM] [Info] Number of data points in the train set: 773, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score 2.412746\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Лучшие параметры для LightGBM: {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'regressor__num_leaves': 31, 'regressor__reg_alpha': 0.1, 'regressor__reg_lambda': 0.5}\n",
      "Лучший R2 на кросс-валидации: 0.3936526185123955\n",
      "\n",
      "Метрики на тестовой выборке (LightGBM):\n",
      "MSE: 0.3145\n",
      "MAE: 0.4082\n",
      "R2: 0.4228\n"
     ]
    }
   ],
   "source": [
    "# Модель 3: LightGBM Регрессор \n",
    "print(\"\\n===== LightGBM Регрессор для CC50 =====\")\n",
    "pipeline_lgbm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LGBMRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Гиперпараметры для настройки LightGBM\n",
    "param_grid_lgbm = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__num_leaves': [31, 63],\n",
    "    'regressor__reg_alpha': [0.1, 0.5],\n",
    "    'regressor__reg_lambda': [0.1, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_lgbm = GridSearchCV(\n",
    "    pipeline_lgbm,\n",
    "    param_grid_lgbm,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='R2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lgbm.fit(X_train_cc50, y_train_cc50)\n",
    "\n",
    "print(\"Лучшие параметры для LightGBM:\", grid_search_lgbm.best_params_)\n",
    "print(\"Лучший R2 на кросс-валидации:\", grid_search_lgbm.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_lgbm = grid_search_lgbm.predict(X_test_cc50)\n",
    "mse_lgbm = mean_squared_error(y_test_cc50, y_pred_lgbm)\n",
    "r2_lgbm = r2_score(y_test_cc50, y_pred_lgbm)\n",
    "mae_lgbm = mean_absolute_error(y_test_cc50, y_pred_lgbm)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (LightGBM):\")\n",
    "print(f\"MSE: {mse_lgbm:.4f}\")\n",
    "print(f\"MAE: {mae_lgbm:.4f}\")\n",
    "print(f\"R2: {r2_lgbm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4216ff35-5064-4d45-8374-168e7316add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== XGBoost Регрессор для CC50 =====\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Лучшие параметры для XGBoost: {'regressor__colsample_bytree': 1.0, 'regressor__learning_rate': 0.05, 'regressor__max_depth': 5, 'regressor__n_estimators': 100, 'regressor__subsample': 0.7}\n",
      "Лучший R2 на кросс-валидации: 0.40138094628762033\n",
      "\n",
      "Метрики на тестовой выборке (XGBoost):\n",
      "MSE: 0.3185\n",
      "MAE: 0.4099\n",
      "R2: 0.4154\n"
     ]
    }
   ],
   "source": [
    "# Модель 4: XGBoost Regressor\n",
    "print(\"\\n===== XGBoost Регрессор для CC50 =====\")\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', XGBRegressor(random_state=42, eval_metric='rmse')) # eval_metric для предотвращения предупреждений\n",
    "])\n",
    "\n",
    "# Гиперпараметры для настройки XGBoost\n",
    "param_grid_xgb = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__subsample': [0.7, 1.0], # Доля выборок для обучения деревьев\n",
    "    'regressor__colsample_bytree': [0.7, 1.0] # Доля признаков для каждого дерева\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='R2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_xgb.fit(X_train_cc50, y_train_cc50)\n",
    "\n",
    "print(\"Лучшие параметры для XGBoost:\", grid_search_xgb.best_params_)\n",
    "print(\"Лучший R2 на кросс-валидации:\", grid_search_xgb.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_xgb = grid_search_xgb.predict(X_test_cc50)\n",
    "mse_xgb = mean_squared_error(y_test_cc50, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test_cc50, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test_cc50, y_pred_xgb)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (XGBoost):\")\n",
    "print(f\"MSE: {mse_xgb:.4f}\")\n",
    "print(f\"MAE: {mae_xgb:.4f}\")\n",
    "print(f\"R2: {r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26413a7-f754-49a3-84a6-a0b62cbb9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CatBoost Регрессор для CC50 =====\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Лучшие параметры для CatBoost: {'regressor__depth': 8, 'regressor__iterations': 100, 'regressor__l2_leaf_reg': 3, 'regressor__learning_rate': 0.1}\n",
      "Лучший R2 на кросс-валидации: 0.40857038816360136\n",
      "\n",
      "Метрики на тестовой выборке (CatBoost):\n",
      "MSE: 0.3033\n",
      "MAE: 0.3986\n",
      "R2: 0.4434\n"
     ]
    }
   ],
   "source": [
    "# Модель 5: CatBoost Regressor\n",
    "print(\"\\n===== CatBoost Регрессор для CC50 =====\")\n",
    "\n",
    "pipeline_cat = Pipeline([\n",
    "    ('scaler', StandardScaler()), # CatBoost менее чувствителен к масштабированию, но для пайплайна оставляем\n",
    "    ('regressor', CatBoostRegressor(random_state=42, verbose=0)) # verbose=0 отключает вывод логов CatBoost\n",
    "])\n",
    "\n",
    "# Гиперпараметры для настройки CatBoost\n",
    "param_grid_cat = {\n",
    "    'regressor__iterations': [100, 200, 300], # Количество итераций (деревьев)\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__depth': [4, 6, 8], # Глубина деревьев\n",
    "    'regressor__l2_leaf_reg': [1, 3, 5] # L2 регуляризация\n",
    "}\n",
    "\n",
    "grid_search_cat = GridSearchCV(\n",
    "    pipeline_cat,\n",
    "    param_grid_cat,\n",
    "    cv=5,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='R2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_cat.fit(X_train_cc50, y_train_cc50)\n",
    "\n",
    "print(\"Лучшие параметры для CatBoost:\", grid_search_cat.best_params_)\n",
    "print(\"Лучший R2 на кросс-валидации:\", grid_search_cat.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_cat = grid_search_cat.predict(X_test_cc50)\n",
    "mse_cat = mean_squared_error(y_test_cc50, y_pred_cat)\n",
    "r2_cat = r2_score(y_test_cc50, y_pred_cat)\n",
    "mae_cat = mean_absolute_error(y_test_cc50, y_pred_cat)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (CatBoost):\")\n",
    "print(f\"MSE: {mse_cat:.4f}\")\n",
    "print(f\"MAE: {mae_cat:.4f}\")\n",
    "print(f\"R2: {r2_cat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3479b287-9228-4410-9d5b-2477ff2caa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Простая Нейронная Сеть для CC50 =====\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для Нейронной Сети: {'regressor__activation': 'relu', 'regressor__batch_size': 32, 'regressor__epochs': 50, 'regressor__hidden_layers': 2, 'regressor__learning_rate': 0.001, 'regressor__neurons': 64, 'regressor__optimizer': 'adam'}\n",
      "Лучший R2 на кросс-валидации: 0.23970444737124044\n",
      "\n",
      "Метрики на тестовой выборке (Нейронная Сеть):\n",
      "MSE: 0.3626\n",
      "MAE: 0.4196\n",
      "R2: 0.3346\n"
     ]
    }
   ],
   "source": [
    "# Модель 6: Простая Нейронная Сеть (Keras Sequential)\n",
    "print(\"\\n===== Простая Нейронная Сеть для CC50 =====\")\n",
    "\n",
    "# Функция для создания Keras-модели\n",
    "# Параметры, которые мы хотим усовершенствовать через GridSearchCV, должны быть аргументами этой функции.\n",
    "def build_nn_model(meta, hidden_layers=1, neurons=32, activation='relu',\n",
    "                     optimizer='adam', learning_rate=0.001):\n",
    "    n_features = meta[\"n_features_in_\"]\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(L.Input(shape=(n_features,)))\n",
    "    \n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(L.Dense(neurons, activation=activation))\n",
    "        \n",
    "    model.add(L.Dense(1)) # Выходной слой для регрессии (1 нейрон, без активации)\n",
    "    \n",
    "    # Создаем экземпляр оптимизатора с указанной скоростью обучения\n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate) # По умолчанию Adam\n",
    "\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Здесь указываем KerasRegressor\n",
    "pipeline_nn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', KerasRegressor(\n",
    "        model=build_nn_model,\n",
    "        # Задаем дефолтные значения для KerasRegressor, они будут переопределяться GridSearchCV\n",
    "        # эти параметры должны быть аргументами build_nn_model\n",
    "        hidden_layers=1,\n",
    "        neurons=32,\n",
    "        activation='relu',\n",
    "        optimizer='adam',\n",
    "        learning_rate=0.001,\n",
    "        batch_size=32, # batch_size и epochs - это параметры .fit(), а не .build_model()\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Гиперпараметры для настройки Нейронной Сети\n",
    "# Параметры указываются с префиксом 'regressor__' для шага 'regressor' в пайплайне\n",
    "# Эти параметры будут переданы в конструктор KerasRegressor, который затем передаст их в build_nn_model.\n",
    "param_grid_nn = {\n",
    "    'regressor__hidden_layers': [1, 2],\n",
    "    'regressor__neurons': [32, 64],\n",
    "    'regressor__activation': ['relu'],\n",
    "    'regressor__optimizer': ['adam'],\n",
    "    'regressor__learning_rate': [0.001, 0.01],\n",
    "    'regressor__batch_size': [32, 64],\n",
    "    'regressor__epochs': [50, 100]\n",
    "}\n",
    "\n",
    "grid_search_nn = GridSearchCV(\n",
    "    pipeline_nn,\n",
    "    param_grid_nn,\n",
    "    cv=3,\n",
    "    scoring=scoring_metrics,\n",
    "    refit='R2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_nn.fit(X_train_cc50, y_train_cc50)\n",
    "\n",
    "print(\"Лучшие параметры для Нейронной Сети:\", grid_search_nn.best_params_)\n",
    "print(\"Лучший R2 на кросс-валидации:\", grid_search_nn.best_score_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "y_pred_nn = grid_search_nn.predict(X_test_cc50)\n",
    "mse_nn = mean_squared_error(y_test_cc50, y_pred_nn)\n",
    "r2_nn = r2_score(y_test_cc50, y_pred_nn)\n",
    "mae_nn = mean_absolute_error(y_test_cc50, y_pred_nn)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке (Нейронная Сеть):\")\n",
    "print(f\"MSE: {mse_nn:.4f}\")\n",
    "print(f\"MAE: {mae_nn:.4f}\")\n",
    "print(f\"R2: {r2_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21377ee-b9e9-42b5-be15-e58ec5f7dfe3",
   "metadata": {},
   "source": [
    "### Анализ результатов для log_CC50, mM\n",
    "## Линейная Регрессия:\n",
    "\n",
    "R2 на кросс-валидации: 0.258\n",
    "R2 на тесте: 0.2913\n",
    "Довольно низкий R2, что ожидаемо для простой линейной модели. MAE в 0.47 означает, что в среднем модель ошибается на 0.47 логарифмических единиц.\n",
    "\n",
    "### Random Forest Регрессор:\n",
    "\n",
    "Лучшие параметры: max_features=0.8, min_samples_leaf=5, n_estimators=200\n",
    "R2 на кросс-валидации: 0.401\n",
    "R2 на тесте: 0.4369. Значительно лучше линейной регрессии. R2 около 0.44 указывает на то, что модель объясняет почти половину дисперсии log_CC50. MAE снизился до 0.4095. \n",
    "\n",
    "### LightGBM Регрессор:\n",
    "\n",
    "Лучшие параметры: learning_rate=0.01, n_estimators=300, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5\n",
    "R2 на кросс-валидации: 0.394\n",
    "R2 на тесте: 0.4228\n",
    "Результаты сопоставимы с Random Forest, чуть ниже на тесте, но все еще значительно лучше линейной модели. Предупреждения LightGBM о \"No further splits\" могут указывать на то, что модель достигала предела своего обучения или данные не содержат достаточно сложных закономерностей для дальнейшего улучшения с текущими параметрами.\n",
    "\n",
    "### XGBoost Регрессор:\n",
    "\n",
    "Лучшие параметры: colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.7\n",
    "R2 на кросс-валидации: 0.401\n",
    "R2 на тесте: 0.4154\n",
    "Также демонстрирует хорошую производительность, сравнимую с Random Forest и LightGBM.\n",
    "\n",
    "### CatBoost Регрессор:\n",
    "\n",
    "Лучшие параметры: depth=8, iterations=100, l2_leaf_reg=3, learning_rate=0.1\n",
    "R2 на кросс-валидации: 0.409\n",
    "R2 на тесте: 0.4434\n",
    "CatBoost показывает лучшие результаты для log_CC50 как на кросс-валидации, так и на тестовой выборке по R2. У него также самый низкий MAE (0.3986), что делает его лучшей моделью для прогнозирования log_CC50.\n",
    "\n",
    "### Простая Нейронная Сеть:\n",
    "\n",
    "Лучшие параметры: activation='relu', batch_size=32, epochs=50, hidden_layers=2, learning_rate=0.001, neurons=64, optimizer='adam'\n",
    "R2 на кросс-валидации: 0.240\n",
    "R2 на тесте: 0.3346\n",
    "Хотя нейронная сеть показала R2 лучше линейной регрессии на тесте, она значительно отстает от бустинговых моделей и Random Forest. Возможно, требуется более сложная архитектура или более обширный поиск гиперпараметров для NN.\n",
    "\n",
    "### Вывод по log_CC50, mM: \n",
    "CatBoost Regressor является лучшей моделью, демонстрируя самый высокий R2 и самый низкий MAE на тестовой выборке. Random Forest и LightGBM также показывают конкурентные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033123d-36aa-428c-99b9-3c874b86f7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
